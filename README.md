# å—å¼€å¤§å­¦æ ¡å†…æœç´¢å¼•æ“ (Nankai University Search Engine)

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)

ä¸€ä¸ªåŸºäº Elasticsearch çš„æ™ºèƒ½æœç´¢å¼•æ“ç³»ç»Ÿï¼Œä¸“é—¨ç”¨äºçˆ¬å–å’Œæœç´¢å—å¼€å¤§å­¦ç½‘ç«™å†…å®¹ã€‚è¯¥é¡¹ç›®å®ç°äº†ç½‘é¡µçˆ¬å–ã€PageRank ç®—æ³•ã€ä¸ªæ€§åŒ–æœç´¢ã€ç”¨æˆ·ç®¡ç†ç­‰åŠŸèƒ½ã€‚

*An intelligent search engine system based on Elasticsearch, specifically designed for crawling and searching Nankai University website content. This project implements web crawling, PageRank algorithm, personalized search, user management, and more.*

## ğŸ“‹ ç›®å½• (Table of Contents)

- [åŠŸèƒ½ç‰¹æ€§](#åŠŸèƒ½ç‰¹æ€§)
- [ç³»ç»Ÿæ¶æ„](#ç³»ç»Ÿæ¶æ„)
- [æŠ€æœ¯æ ˆ](#æŠ€æœ¯æ ˆ)
- [å‰ç½®è¦æ±‚](#å‰ç½®è¦æ±‚)
- [å®‰è£…æŒ‡å—](#å®‰è£…æŒ‡å—)
- [é…ç½®è¯´æ˜](#é…ç½®è¯´æ˜)
- [ä½¿ç”¨è¯´æ˜](#ä½¿ç”¨è¯´æ˜)
- [é¡¹ç›®ç»“æ„](#é¡¹ç›®ç»“æ„)
- [æŠ€æœ¯ç»†èŠ‚](#æŠ€æœ¯ç»†èŠ‚)
- [è´¡çŒ®æŒ‡å—](#è´¡çŒ®æŒ‡å—)
- [è®¸å¯è¯](#è®¸å¯è¯)

## âœ¨ åŠŸèƒ½ç‰¹æ€§ (Features)

### æ ¸å¿ƒåŠŸèƒ½
- **ğŸ•·ï¸ æ™ºèƒ½ç½‘é¡µçˆ¬è™«**: åŸºäº Scrapy çš„åˆ†å¸ƒå¼ç½‘é¡µçˆ¬è™«ï¼Œæ”¯æŒæ·±åº¦çˆ¬å–å’Œå¹¶å‘æ§åˆ¶
- **ğŸ” å¤šç§æŸ¥è¯¢æ–¹å¼**:
  - çŸ­è¯­æŸ¥è¯¢ (Phrase Query)
  - é€šé…ç¬¦æŸ¥è¯¢ (Wildcard Query)
  - è”æƒ³æœç´¢å»ºè®® (Auto-suggestion)
- **ğŸ“Š PageRank ç®—æ³•**: åŸºäºç½‘é¡µé“¾æ¥å…³ç³»è®¡ç®—é¡µé¢é‡è¦æ€§
- **ğŸ‘¤ ç”¨æˆ·ç®¡ç†ç³»ç»Ÿ**: æ”¯æŒç”¨æˆ·æ³¨å†Œã€ç™»å½•å’Œä¸ªæ€§åŒ–åŠŸèƒ½
- **ğŸ“ˆ ä¸ªæ€§åŒ–æœç´¢**: åŸºäºç”¨æˆ·å†å²è®°å½•ä¼˜åŒ–æœç´¢ç»“æœ
- **ğŸ’¾ æœç´¢å†å²è®°å½•**: è‡ªåŠ¨è®°å½•å’Œç®¡ç†ç”¨æˆ·æœç´¢å†å²
- **âš¡ é«˜æ€§èƒ½ç´¢å¼•**: ä½¿ç”¨ Elasticsearch å®ç°å¿«é€Ÿå…¨æ–‡æ£€ç´¢

### æœç´¢ç®—æ³•ä¼˜åŒ–
- TF-IDF æƒé‡è®¡ç®—
- PageRank ç½‘é¡µæ’å
- ä¸ªæ€§åŒ–ç»“æœæ’åºï¼ˆ70% TF-IDF + 30% PageRankï¼‰
- åŸºäºç”¨æˆ·å†å²çš„ç»“æœå¢å¼º

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„ (System Architecture)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ç”¨æˆ·ç•Œé¢      â”‚
â”‚  (CLI Interface)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æœç´¢å¼•æ“æ ¸å¿ƒ   â”‚
â”‚ (Search Engine) â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ ç”¨æˆ·ç®¡ç†      â”‚
â”‚ â€¢ æŸ¥è¯¢å¤„ç†      â”‚
â”‚ â€¢ ç»“æœæ’åº      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Elasticsearch  â”‚
â”‚   (ç´¢å¼•å­˜å‚¨)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   æ•°æ®å¤„ç†å±‚    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ ç½‘é¡µçˆ¬å–      â”‚
â”‚ â€¢ PageRank è®¡ç®— â”‚
â”‚ â€¢ æ•°æ®ä¸Šä¼       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ æŠ€æœ¯æ ˆ (Tech Stack)

- **Python 3.8+**: ä¸»è¦ç¼–ç¨‹è¯­è¨€
- **Elasticsearch 7.x+**: å…¨æ–‡æ£€ç´¢å¼•æ“
- **Scrapy**: ç½‘é¡µçˆ¬è™«æ¡†æ¶
- **NetworkX**: å›¾è®ºå’Œ PageRank è®¡ç®—
- **Pandas**: æ•°æ®å¤„ç†å’Œåˆ†æ
- **å…¶ä»–ä¾èµ–**: tqdm, hashlib, json

## ğŸ“¦ å‰ç½®è¦æ±‚ (Prerequisites)

åœ¨å¼€å§‹ä¹‹å‰ï¼Œè¯·ç¡®ä¿æ‚¨çš„ç³»ç»Ÿå·²å®‰è£…ä»¥ä¸‹è½¯ä»¶ï¼š

### å¿…éœ€è½¯ä»¶
1. **Python 3.8 æˆ–æ›´é«˜ç‰ˆæœ¬**
   ```bash
   python --version  # æ£€æŸ¥ç‰ˆæœ¬
   ```

2. **Elasticsearch 7.x æˆ–æ›´é«˜ç‰ˆæœ¬**
   - ä¸‹è½½åœ°å€: https://www.elastic.co/downloads/elasticsearch
   - ç¡®ä¿ Elasticsearch æœåŠ¡è¿è¡Œåœ¨ `http://localhost:9200`

### Python ä¾èµ–åŒ…
```bash
pip install elasticsearch
pip install scrapy
pip install pandas
pip install networkx
pip install tqdm
```

## ğŸš€ å®‰è£…æŒ‡å— (Installation)

### 1. å…‹éš†ä»“åº“
```bash
git clone https://github.com/MengQxuan/information-retrieval.git
cd information-retrieval
```

### 2. å®‰è£…ä¾èµ–
```bash
pip install elasticsearch scrapy pandas networkx tqdm
```

### 3. å¯åŠ¨ Elasticsearch
```bash
# ä¸‹è½½å¹¶è§£å‹ Elasticsearch
# åœ¨ Elasticsearch ç›®å½•ä¸‹è¿è¡Œ:
./bin/elasticsearch  # Linux/Mac
# æˆ–
bin\elasticsearch.bat  # Windows

# éªŒè¯ Elasticsearch æ˜¯å¦è¿è¡Œ
curl http://localhost:9200
```

### 4. éªŒè¯å®‰è£…
```bash
cd code
python search.py
```

## âš™ï¸ é…ç½®è¯´æ˜ (Configuration)

### Elasticsearch é…ç½®
åœ¨ `code/search.py` ä¸­ä¿®æ”¹ Elasticsearch é…ç½®ï¼š

```python
ES_HOST = 'http://localhost:9200'  # Elasticsearch ä¸»æœºåœ°å€
INDEX_NAME = 'xxjs'                 # ç´¢å¼•åç§°
```

### çˆ¬è™«é…ç½®
åœ¨ `code/settings.py` ä¸­è°ƒæ•´çˆ¬è™«å‚æ•°ï¼š

```python
DOWNLOAD_DELAY = 0.15              # ä¸‹è½½å»¶è¿Ÿï¼ˆç§’ï¼‰
DEPTH_LIMIT = 100                  # çˆ¬å–æ·±åº¦é™åˆ¶
CONCURRENT_REQUESTS = 32           # æœ€å¤§å¹¶å‘è¯·æ±‚æ•°
CONCURRENT_REQUESTS_PER_DOMAIN = 16  # å•åŸŸå¹¶å‘é™åˆ¶
```

### PageRank é…ç½®
åœ¨ `code/pagerank.py` ä¸­ä¿®æ”¹è¾“å…¥æ–‡ä»¶ï¼š

```python
csv_file_path = "cleanednkuoutput.csv"  # çˆ¬å–æ•°æ®æ–‡ä»¶è·¯å¾„
```

## ğŸ“– ä½¿ç”¨è¯´æ˜ (Usage)

### å®Œæ•´å·¥ä½œæµç¨‹

#### æ­¥éª¤ 1: çˆ¬å–ç½‘é¡µæ•°æ®
```bash
cd code
scrapy crawl nku
# è¿™å°†ç”Ÿæˆ nku_output.csv æ–‡ä»¶
```

#### æ­¥éª¤ 2: è®¡ç®— PageRank
```bash
python pagerank.py
# è¾“å…¥: cleanednkuoutput.csv
# è¾“å‡º: pangerankedData/pangerankedoutput.csv
```

#### æ­¥éª¤ 3: ç”Ÿæˆæœç´¢å»ºè®®
```bash
python suggest.py
# è¾“å…¥: pagerankedoutput.csv
# è¾“å‡º: finaloutput.csv
```

#### æ­¥éª¤ 4: ä¸Šä¼ æ•°æ®åˆ° Elasticsearch
```bash
python dataup.py
# å°† finaloutput.csv ä¸Šä¼ åˆ° Elasticsearch
```

#### æ­¥éª¤ 5: ä½¿ç”¨æœç´¢å¼•æ“
```bash
python search.py
```

### æœç´¢å¼•æ“åŠŸèƒ½

å¯åŠ¨æœç´¢å¼•æ“åï¼Œæ‚¨å¯ä»¥ï¼š

1. **æ³¨å†Œæ–°ç”¨æˆ·**
   - è¾“å…¥å”¯ä¸€çš„ç”¨æˆ·å
   - è®¾ç½®å¹¶ç¡®è®¤å¯†ç 

2. **ç™»å½•ç³»ç»Ÿ**
   - ä½¿ç”¨å·²æ³¨å†Œçš„ç”¨æˆ·åå’Œå¯†ç 

3. **æ‰§è¡Œæœç´¢**
   - **çŸ­è¯­æŸ¥è¯¢**: æœç´¢ç²¾ç¡®åŒ¹é…çš„çŸ­è¯­
   - **é€šé…ç¬¦æŸ¥è¯¢**: ä½¿ç”¨ `*` å’Œ `?` è¿›è¡Œæ¨¡ç³Šæœç´¢
   - **è”æƒ³æœç´¢**: è¾“å…¥å‰ç¼€è·å–æœç´¢å»ºè®®

4. **æŸ¥çœ‹å†å²è®°å½•**
   - æŸ¥çœ‹ä¸ªäººæœç´¢å†å²

5. **é€€å‡ºç™»å½•**

### ä½¿ç”¨ç¤ºä¾‹

```
===== æ¬¢è¿ä½¿ç”¨å—å¼€å¤§å­¦æœç´¢å¼•æ“ =====
è¯·é€‰æ‹©æ“ä½œ:
1. æ³¨å†Œ
2. ç™»å½•
3. é€€å‡º
è¾“å…¥æ•°å­—é€‰æ‹©æ“ä½œ: 2

===== ç™»å½• =====
è¯·è¾“å…¥ç”¨æˆ·å: testuser
è¯·è¾“å…¥å¯†ç : ******
ç”¨æˆ· 'testuser' ç™»å½•æˆåŠŸï¼

===== æœç´¢å¼•æ“ =====
é€‰æ‹©æŸ¥è¯¢ç±»å‹:
1. çŸ­è¯­æŸ¥è¯¢
2. é€šé…æŸ¥è¯¢
3. è”æƒ³å…³è”ï¼ˆæœç´¢å»ºè®®ï¼‰
4. æŸ¥çœ‹æŸ¥è¯¢å†å²
5. é€€å‡ºç™»å½•
è¾“å…¥æ•°å­—é€‰æ‹©æ“ä½œ: 1

è¯·è¾“å…¥çŸ­è¯­æŸ¥è¯¢: å—å¼€å¤§å­¦

===== æœç´¢ç»“æœ =====
Rank 1:
Title: å—å¼€å¤§å­¦é¦–é¡µ
URL: http://www.nankai.edu.cn/
Final Score: 0.856234
Snippet: å—å¼€å¤§å­¦æ˜¯å›½å†…å­¦æœ¯åº•è•´æ·±åš...
```

## ğŸ“ é¡¹ç›®ç»“æ„ (Project Structure)

```
information-retrieval/
â”‚
â”œâ”€â”€ README.md                 # é¡¹ç›®è¯´æ˜æ–‡æ¡£
â”œâ”€â”€ è¯´æ˜æ–‡æ¡£.pdf              # è¯¦ç»†è¯´æ˜æ–‡æ¡£
â”‚
â””â”€â”€ code/                     # æºä»£ç ç›®å½•
    â”œâ”€â”€ nku_spider.py         # Scrapy çˆ¬è™«å®ç°
    â”œâ”€â”€ settings.py           # Scrapy é…ç½®æ–‡ä»¶
    â”œâ”€â”€ pagerank.py           # PageRank ç®—æ³•å®ç°
    â”œâ”€â”€ suggest.py            # æœç´¢å»ºè®®ç”Ÿæˆ
    â”œâ”€â”€ dataup.py             # æ•°æ®ä¸Šä¼ åˆ° Elasticsearch
    â”œâ”€â”€ search.py             # æœç´¢å¼•æ“ä¸»ç¨‹åº
    â”œâ”€â”€ users.json            # ç”¨æˆ·æ•°æ®å­˜å‚¨
    â””â”€â”€ history.txt           # æœç´¢å†å²è®°å½•
```

### ä¸»è¦æ¨¡å—è¯´æ˜

#### `nku_spider.py` - ç½‘é¡µçˆ¬è™«
- ä½¿ç”¨ Scrapy æ¡†æ¶çˆ¬å–å—å¼€å¤§å­¦ç½‘ç«™
- æå–æ ‡é¢˜ã€URLã€æ­£æ–‡å†…å®¹å’Œé“¾æ¥
- è¾“å‡º CSV æ ¼å¼æ•°æ®

#### `pagerank.py` - PageRank è®¡ç®—
- åŸºäº NetworkX æ„å»ºç½‘é¡µé“¾æ¥å›¾
- è®¡ç®—æ¯ä¸ªé¡µé¢çš„ PageRank å€¼
- æ›´æ–° CSV æ•°æ®æ·»åŠ  PageRank å­—æ®µ

#### `suggest.py` - æœç´¢å»ºè®®
- åŸºäºé¡µé¢æ ‡é¢˜ç”Ÿæˆæœç´¢å»ºè®®
- ä¸º Elasticsearch çš„ completion suggester å‡†å¤‡æ•°æ®

#### `dataup.py` - æ•°æ®ä¸Šä¼ 
- æ‰¹é‡ä¸Šä¼ æ•°æ®åˆ° Elasticsearch
- åˆ›å»ºç´¢å¼•å’Œæ˜ å°„
- é”™è¯¯å¤„ç†å’Œè¿›åº¦æ˜¾ç¤º

#### `search.py` - æœç´¢å¼•æ“æ ¸å¿ƒ
åŒ…å«ä»¥ä¸‹ç±»å’ŒåŠŸèƒ½ï¼š

**User ç±»**:
- ç”¨æˆ·æ³¨å†Œå’Œç™»å½•
- å¯†ç å“ˆå¸ŒåŠ å¯†
- ç”¨æˆ·çŠ¶æ€ç®¡ç†

**SearchEngine ç±»**:
- çŸ­è¯­æŸ¥è¯¢å’Œé€šé…ç¬¦æŸ¥è¯¢
- ç»“æœæ’åºï¼ˆTF-IDF + PageRankï¼‰
- ä¸ªæ€§åŒ–æœç´¢ä¼˜åŒ–
- æœç´¢å†å²è®°å½•
- æœç´¢å»ºè®®åŠŸèƒ½

## ğŸ”¬ æŠ€æœ¯ç»†èŠ‚ (Technical Details)

### PageRank ç®—æ³•
```python
# ä½¿ç”¨ NetworkX è®¡ç®— PageRank
G = nx.DiGraph()
# æ·»åŠ ç½‘é¡µå’Œé“¾æ¥è¾¹
pagerank = nx.pagerank(G, alpha=0.85)
```

### æœç´¢ç»“æœæ’åº
```python
# ç»¼åˆå¾—åˆ†è®¡ç®—
final_score = 0.7 * normalized_tfidf + 0.3 * normalized_pagerank

# ä¸ªæ€§åŒ–å¢å¼º
if user_history:
    boost_weight = 1.5  # å†å²ç›¸å…³ç»“æœæå‡æƒé‡
```

### Elasticsearch æ˜ å°„
```json
{
  "mappings": {
    "properties": {
      "title": {"type": "text"},
      "url": {"type": "keyword"},
      "text": {"type": "text"},
      "pagerank": {"type": "float"},
      "suggest": {"type": "completion"}
    }
  }
}
```

### å®‰å…¨æ€§
- å¯†ç ä½¿ç”¨ SHA-256 å“ˆå¸ŒåŠ å¯†
- æ”¯æŒç›å€¼ (salt) å¢å¼ºå®‰å…¨æ€§
- ç”¨æˆ·æ•°æ®æœ¬åœ°å­˜å‚¨

## ğŸ¤ è´¡çŒ®æŒ‡å— (Contributing)

æ¬¢è¿è´¡çŒ®ä»£ç ï¼è¯·éµå¾ªä»¥ä¸‹æ­¥éª¤ï¼š

1. Fork æœ¬ä»“åº“
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. å¼€å¯ Pull Request

### ä»£ç è§„èŒƒ
- éµå¾ª PEP 8 Python ä»£ç è§„èŒƒ
- æ·»åŠ é€‚å½“çš„æ³¨é‡Šå’Œæ–‡æ¡£
- ç¡®ä¿ä»£ç é€šè¿‡æµ‹è¯•

## ğŸ“ è®¸å¯è¯ (License)

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ã€‚è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

## ğŸ”— ç›¸å…³èµ„æº (Related Resources)

- [Elasticsearch å®˜æ–¹æ–‡æ¡£](https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html)
- [Scrapy æ–‡æ¡£](https://docs.scrapy.org/)
- [NetworkX æ–‡æ¡£](https://networkx.org/documentation/stable/)
- [PageRank ç®—æ³•ä»‹ç»](https://en.wikipedia.org/wiki/PageRank)
